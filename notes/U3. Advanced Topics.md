# **<u>Recurrent Neural Network</u>**

## **RNN**

- “Vanilla” Neural Network
  - one to one
- Recurrent Neural Networks: Process Sequences
  - ​	<img src="image.assets/Screen Shot 2022-03-21 at 11.56.44.png" alt="Screen Shot 2022-03-21 at 11.56.44" style="zoom:20%;" />
    - one to many
      - e.g. Image Captioning: image -> sequence of words
    - many to one
      - e.g. Sentiment Classification: sequence of words -> sentiment
    - many to many
      - e.g. Machine Translation: seq of words -> seq of words
    - many to many
      - e.g. Video classification on frame level
  - Sequential Processing of Non-Sequence Data
    - e.g. Classify images by taking a series of “glimpses”
    - e.g. Generate images one piece at a time

### Recurrent Neural Network

- ​	<img src="image.assets/Screen Shot 2022-03-21 at 12.09.57.png" alt="Screen Shot 2022-03-21 at 12.09.57" style="zoom:20%;" />
- We can process a sequence of vectors x by applying a recurrence formula at every time step:
  $$
  h_{t}=f_{W}\left(h_{t-1}, x_{t}\right)
  $$
  - Notice: the same function and the same set of parameters are used at every time step.
  - e.g.
  	$$
    \begin{aligned}
    &h_{t}=\tanh \left(W_{h h} h_{t-1}+W_{x h} x_{t}\right) \\
    &y_{t}=W_{h y} h_{t}
    \end{aligned}
    $$
- RNN: Computational Graph: e.g. Many to Many
  - ​	<img src="image.assets/Screen Shot 2022-03-21 at 12.14.22.png" alt="Screen Shot 2022-03-21 at 12.14.22" style="zoom:20%;" />

### Image Captioning

- Input to RNN: CNN without classification layers
  - ​	<img src="image.assets/Screen Shot 2022-03-21 at 12.34.31.png" alt="Screen Shot 2022-03-21 at 12.34.31" style="zoom:15%;" />
- RNN first unit
  - before: $h=\tanh \left(W _{x h} * x+W _{h h} * h\right)$
  - after: $h=\tanh \left(W _{x h} * x+W _{h h}* h+W _{i h} * v\right)$

### Image Captioning with Attention

- RNN focuses its attention at a different spatial location when generating each word
  - ​	<img src="image.assets/Screen Shot 2022-03-21 at 15.05.14.png" alt="Screen Shot 2022-03-21 at 15.05.14" style="zoom:20%;" />

### Vanilla RNN Gradient Flow

- Largest singular value > 1: Exploding gradients
  - Gradient clipping: Scale gradient if its norm is too big
- Largest singular value < 1: Vanishing gradients
  - Change RNN architecture -> LSTM

# **<u>Visualizing and Understanding</u>**

- First Layer: Visualize Filters
- Last Layer: Nearest Neighbors
- Last Layer: Dimensionality Reduction
- Maximally Activating Patches
- Occlusion Experiments

### Saliency Maps

- ​	<img src="image.assets/Screen Shot 2022-03-21 at 19.39.02.png" alt="Screen Shot 2022-03-21 at 19.39.02" style="zoom:25%;" />
  - How to tell which pixels matter for classification?
    - Compute gradient of (unnormalized) class score with respect to image pixels, take absolute value and max over RGB channels
- Saliency Maps: Segmentation without supervision

### Intermediate features via (guided) backprop

- ​	<img src="image.assets/Screen Shot 2022-03-21 at 19.38.19.png" alt="Screen Shot 2022-03-21 at 19.38.19" style="zoom:25%;" />
  - Pick a single intermediate neuron, e.g. one value in 128 x 13 x 13 conv5 feature map 
  - Compute gradient of neuron value with respect to image pixels

### Visualizing CNN features: Gradient Ascent

- ​	<img src="image.assets/Screen Shot 2022-03-21 at 19.40.34.png" alt="Screen Shot 2022-03-21 at 19.40.34" style="zoom: 33%;" />
  
  - Generate a synthetic image that maximally activates a neuron
    - Initialize image to zeros
    - Repeat:
      - Forward image to compute current scores
      - Backprop to get gradient of neuron value with respect to image pixels
      - Make a small update to the image
  - $\arg \max _{I} S_{c}(I)-\lambda\|I\|_{2}^{2}$
    - Simple regularizer: Penalize L2 norm of generated image
    - Better regularizer: Penalize L2 norm of image; also during optimization periodically 
      - Gaussian blur image 
      - Clip pixels with small values to 0 
      - Clip pixels with small gradients to 0
    - Adding “multi-faceted” visualization gives even nicer results: (Plus more careful regularization, center-bias)
  - Optimize in FC6 latent space instead of pixel space
    - ​	<img src="image.assets/Screen Shot 2022-03-21 at 19.44.48.png" alt="Screen Shot 2022-03-21 at 19.44.48" style="zoom:33%;" />

### Fooling Images / Adversarial Examples

1. Start from an ify the image to maximize the class
4. Repeat until network is fooled

### DeepDream: Amplify existing features

- Rather than synthesizing an image to maximize a specific neuron, instead try to amplify the neuron activations at some layer in the network
  - Choose an image and a layer in a CNN; repeat: 
    1. Forward: compute activations at chosen layer 
    2. Set gradient of chosen layer equal to its activation 
    3. Backward: Compute gradient on image 
    4. Update image

### Others

- Feature Inversion
- Texture Synthesis
  - Neural Texture Synthesis: Gram Matrix
  - Neural Texture Synthesis: Texture = Artwork
    - Feature + Gram Reconstruction
    - **Neural Style Transfer**
      - see Lecture12 for detail



# **<u>Lectures</u>**

### In Lecture 13

- unsupervised Learning
  - examples
    - clustering
    - dimension reduction
    - feature representation
    - density estimation
  - training data is cheap
  - understand structure of visual world
- generative models
- PixelRNN and PixelCNN
  - sequential generation => slow
- Variational Autoencoders (VAE)
- Generative Adversarial Networks (GAN)

### In Lecture 14

- reinforcement learning
  - Markov Decision Processes
  - Q-Learning
  - Policy Gradients

### In Lecture 15

- Part 1: Algorithms for Efficient Inference
  - Pruning
  - Weight Sharing
  - Quantization
  - Low Rank Approximation
  - Binary / Ternary Net
  - Winograd Transformation
- Part 2: Hardware for Efficient Inference
- Part 3: Algorithms for Efficient Training
  - Parallelization
  - Mixed Precision with FP16 and FP32
  - Model Distillation
  - DSD: Dense-Sparse-Dense Training
- Part 4: Hardware for Efficient Training

### In Lecture 16

- adversarial examples
  - somewhat resistant 
    - RBF Network
    - Partisan Density Estimators
  - from overfitting
  - from excessive linearity (underfitting)
    - Modern deep nets are very piecewise linear































